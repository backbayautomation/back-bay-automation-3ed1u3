# Enhanced Alembic configuration for AI-powered Product Catalog Search System
# version: 1.12.0

[alembic]
# Path to migration scripts
script_location = migrations

# Template used to generate migration file names
file_template = %%(year)d_%%(month).2d_%%(day).2d_%%(hour).2d%%(minute).2d-%%(rev)s_%%(slug)s

# Timezone configuration
timezone = UTC

# Maximum length of migration file names
truncate_slug_length = 40

# Enable Python scripts in migrations
revision_environment = true

# Disable sourceless migrations
sourceless = false

# Multi-tenant version locations
version_locations = %(here)s/versions/%(tenant)s

# Path separator for version locations
version_path_separator = os

# Database connection URL with environment variables
sqlalchemy.url = postgresql+psycopg2://${POSTGRES_USER}:${POSTGRES_PASSWORD}@${POSTGRES_HOST}:${POSTGRES_PORT}/${POSTGRES_DB}

# SSL configuration
ssl_mode = verify-full

# Connection timeout in seconds
connect_timeout = 10

# Connection pool settings
pool_size = 5
max_overflow = 10
pool_timeout = 30
pool_recycle = 1800

# Compare type and server default during migrations
compare_type = true
compare_server_default = true

# Enable transaction per migration
transaction_per_migration = true

[loggers]
keys = root,sqlalchemy,alembic,tenant

[logger_root]
level = INFO
handlers = console,file,json
qualname = 
formatter = json

[logger_sqlalchemy]
level = INFO
handlers = console,file,json
qualname = sqlalchemy.engine
formatter = json
tenant_context = true
performance_metrics = true

[logger_alembic]
level = INFO
handlers = console,file,json
qualname = alembic
formatter = json
audit_logging = true

[logger_tenant]
level = INFO
handlers = console,file,json
qualname = tenant
formatter = json
tenant_context = true

[handlers]
keys = console,file,json

[handler_console]
class = logging.StreamHandler
level = INFO
formatter = json
args = (sys.stderr,)

[handler_file]
class = logging.handlers.RotatingFileHandler
level = DEBUG
formatter = json
args = ('/var/log/alembic/migrations.log', 'a', 10485760, 5)
file_maxBytes = 10485760
file_backupCount = 5

[handler_json]
class = pythonjsonlogger.jsonlogger.JsonFormatter
level = INFO
formatter = json

[formatters]
keys = generic,json

[formatter_generic]
format = %(levelname)-5.5s [%(name)s] %(message)s
datefmt = %Y-%m-%d %H:%M:%S

[formatter_json]
format = %(asctime)s %(levelname)s %(name)s %(tenant)s %(message)s
datefmt = %Y-%m-%d %H:%M:%S
include_tenant = true
include_trace_id = true