# Alertmanager v0.25.0
# prometheus-operator v0.68.0

---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: alertmanager
  namespace: monitoring
  labels:
    app: alertmanager
    component: monitoring
    tier: control-plane
spec:
  replicas: 3
  podManagementPolicy: Parallel
  updateStrategy:
    type: RollingUpdate
  selector:
    matchLabels:
      app: alertmanager
  template:
    metadata:
      labels:
        app: alertmanager
      annotations:
        prometheus.io/scrape: "true"
        prometheus.io/port: "9093"
    spec:
      affinity:
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            - topologyKey: kubernetes.io/hostname
              labelSelector:
                matchLabels:
                  app: alertmanager
      securityContext:
        fsGroup: 2000
        runAsNonRoot: true
        runAsUser: 1000
      containers:
        - name: alertmanager
          image: prom/alertmanager:v0.25.0
          args:
            - --config.file=/etc/alertmanager/alertmanager.yml
            - --storage.path=/alertmanager
            - --cluster.listen-address=0.0.0.0:9094
            - --cluster.peer=alertmanager-0.alertmanager:9094
            - --cluster.peer=alertmanager-1.alertmanager:9094
            - --cluster.peer=alertmanager-2.alertmanager:9094
            - --web.external-url=https://alerts.product-search.com
          ports:
            - containerPort: 9093
              name: web
              protocol: TCP
            - containerPort: 9094
              name: cluster
              protocol: TCP
          resources:
            requests:
              cpu: "200m"
              memory: "512Mi"
            limits:
              cpu: "400m"
              memory: "1Gi"
          livenessProbe:
            httpGet:
              path: /-/healthy
              port: 9093
            initialDelaySeconds: 30
            timeoutSeconds: 5
          readinessProbe:
            httpGet:
              path: /-/ready
              port: 9093
            initialDelaySeconds: 15
            timeoutSeconds: 5
          volumeMounts:
            - name: config-volume
              mountPath: /etc/alertmanager
            - name: alertmanager-storage
              mountPath: /alertmanager
      volumes:
        - name: config-volume
          configMap:
            name: alertmanager-config
  volumeClaimTemplates:
    - metadata:
        name: alertmanager-storage
      spec:
        accessModes:
          - ReadWriteOnce
        storageClassName: managed-premium
        resources:
          requests:
            storage: 10Gi

---
apiVersion: v1
kind: Service
metadata:
  name: alertmanager
  namespace: monitoring
  labels:
    app: alertmanager
    component: monitoring
spec:
  type: ClusterIP
  ports:
    - port: 9093
      targetPort: 9093
      name: web
      protocol: TCP
    - port: 9094
      targetPort: 9094
      name: cluster
      protocol: TCP
  selector:
    app: alertmanager

---
apiVersion: v1
kind: ConfigMap
metadata:
  name: alertmanager-config
  namespace: monitoring
data:
  alertmanager.yml: |
    global:
      resolve_timeout: 5m
      slack_api_url: ${SLACK_WEBHOOK_URL}
      pagerduty_url: https://events.pagerduty.com/v2/enqueue
      smtp_smarthost: smtp.product-search.com:587
      smtp_from: alerts@product-search.com
      smtp_auth_username: ${SMTP_USERNAME}
      smtp_auth_password: ${SMTP_PASSWORD}

    route:
      group_by: ['alertname', 'cluster', 'service', 'severity']
      group_wait: 30s
      group_interval: 5m
      repeat_interval: 4h
      receiver: slack-notifications
      routes:
        - match:
            severity: critical
          receiver: pagerduty-critical
          group_wait: 0s
          repeat_interval: 1h
        - match:
            severity: warning
            type: security
          receiver: security-team
          group_wait: 30s
        - match:
            severity: warning
          receiver: slack-notifications
          group_wait: 1m

    receivers:
      - name: slack-notifications
        slack_configs:
          - channel: '#alerts-prod'
            send_resolved: true
            title: '[{{ .Status | toUpper }}] {{ .CommonLabels.alertname }}'
            text: |
              {{ range .Alerts }}
              *Alert:* {{ .Annotations.summary }}
              *Description:* {{ .Annotations.description }}
              *Severity:* {{ .Labels.severity }}
              *Service:* {{ .Labels.service }}
              *Started:* {{ .StartsAt }}
              {{ end }}

      - name: pagerduty-critical
        pagerduty_configs:
          - service_key: ${PAGERDUTY_SERVICE_KEY}
            description: '{{ .CommonLabels.alertname }}'
            severity: '{{ .CommonLabels.severity }}'
            details:
              firing: '{{ .Alerts.Firing | len }}'
              resolved: '{{ .Alerts.Resolved | len }}'
              num_firing: '{{ .Alerts.Firing | len }}'

      - name: security-team
        email_configs:
          - to: security@product-search.com
            send_resolved: true
            headers:
              subject: '[SECURITY] {{ .CommonLabels.alertname }}'
        slack_configs:
          - channel: '#security-alerts'
            send_resolved: true
            title: '[SECURITY] {{ .CommonLabels.alertname }}'
            text: |
              {{ range .Alerts }}
              *Security Alert:* {{ .Annotations.summary }}
              *Impact:* {{ .Annotations.description }}
              *Severity:* {{ .Labels.severity }}
              {{ end }}

    inhibit_rules:
      - source_match:
          severity: critical
        target_match:
          severity: warning
        equal: ['alertname', 'cluster', 'service']