apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: backend-hpa
  namespace: product-search
  labels:
    app: backend
    component: api
    environment: production
  annotations:
    # Enable Kubernetes metrics monitoring
    monitoring.kubernetes.io/enable: "true"
    # Indicate stable scaling behavior
    scaling.kubernetes.io/behavior: "stable"
    # Document HPA version and configuration
    app.kubernetes.io/version: "v1.25+"
    app.kubernetes.io/description: "Backend service HPA with multi-metric scaling"

spec:
  # Target the backend deployment for scaling
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: backend

  # Scaling limits based on production requirements
  minReplicas: 3
  maxReplicas: 20

  # Multi-metric scaling configuration
  metrics:
    # CPU-based scaling
    - type: Resource
      resource:
        name: cpu
        target:
          type: Utilization
          averageUtilization: 75

    # Memory-based scaling
    - type: Resource
      resource:
        name: memory
        target:
          type: Utilization
          averageUtilization: 80

    # GPU utilization scaling
    - type: Resource
      resource:
        name: nvidia.com/gpu
        target:
          type: Utilization
          averageUtilization: 80

  # Scaling behavior controls
  behavior:
    # Scale up behavior
    scaleUp:
      # Wait 60s before scaling up again
      stabilizationWindowSeconds: 60
      policies:
        # Add max 2 pods per minute
        - type: Pods
          value: 2
          periodSeconds: 60
      # Use the most aggressive policy
      selectPolicy: Max

    # Scale down behavior
    scaleDown:
      # Wait 5 minutes before scaling down
      stabilizationWindowSeconds: 300
      policies:
        # Remove max 1 pod per minute
        - type: Pods
          value: 1
          periodSeconds: 60
      # Use the most conservative policy
      selectPolicy: Min